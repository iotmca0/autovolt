# AutoVolt Voice Control System - Complete Technical Documentation

## üéØ Overview

AutoVolt's voice control system enables hands-free classroom device management through natural language processing. It supports **web-based voice recognition** and integration with major voice assistants (Google Assistant, Alexa, and Siri/HomeKit).

---

## üèóÔ∏è Architecture

### System Components

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React + TypeScript)             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ  ‚îÇ Web Speech API   ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ Voice Intents   ‚îÇ                 ‚îÇ
‚îÇ  ‚îÇ (Browser Native) ‚îÇ   ‚îÇ Parser (Local)  ‚îÇ                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ           ‚îÇ                      ‚îÇ                           ‚îÇ
‚îÇ           ‚ñº                      ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ  ‚îÇ  Voice Log Service (Analytics)        ‚îÇ                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ HTTPS/WSS
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 BACKEND (Node.js + Express)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ  ‚îÇ Voice Assistant Controller                 ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Natural Language Processing (Fuse.js)   ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Intent Recognition & Device Matching    ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Context Management (Follow-up Commands) ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Bulk Operation Confirmation             ‚îÇ             ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Permission & Access Control             ‚îÇ             ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                        ‚îÇ                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ          Voice Auth Middleware            ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Session-based Token Auth               ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Rate Limiting (100 cmds/15min)         ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Role Permission Validation             ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ                        ‚îÇ                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ    Integration Handlers                   ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Google Assistant (Smart Home API)      ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Amazon Alexa (Smart Home Skill)        ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Siri/HomeKit (Webhook)                 ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ MongoDB + MQTT
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   IoT LAYER (ESP32)                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ Physical Devices (Relays, Switches)       ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üé§ Technologies Used

### Frontend Stack

1. **Web Speech API** (Browser Native)
   - **Purpose**: Real-time speech-to-text conversion
   - **Browser Support**: Chrome, Edge, Safari (webkit)
   - **Features**:
     - Continuous listening mode
     - Interim results (real-time transcription)
     - Final results with confidence scores
     - Language selection (English, Hindi, etc.)

2. **Fuse.js** (Fuzzy Matching)
   - **Purpose**: Flexible intent parsing
   - **Threshold**: 0.4 (40% similarity required)
   - **Use Cases**:
     - Device name matching ("light" vs "lights")
     - Room/classroom matching
     - Action synonym detection

3. **TypeScript**
   - **Purpose**: Type-safe voice intent structures
   - **Key Interfaces**:
     - `VoiceIntentType`: Intent classification
     - `ParsedVoiceIntent`: Parsed command structure

### Backend Stack

1. **Fuse.js** (Advanced Fuzzy Search)
   - **Purpose**: Device and switch matching
   - **Threshold**: 0.4 (configurable per search)
   - **Features**:
     - Multi-field matching (name, classroom, location, aliases)
     - Score-based ranking
     - Context-aware filtering

2. **Express.js**
   - **Purpose**: RESTful API endpoints
   - **Routes**:
     - `/api/voice-assistant/session/*` - Session management
     - `/api/voice-assistant/voice/command` - Command processing
     - `/api/voice-assistant/google/*` - Google Assistant integration
     - `/api/voice-assistant/alexa/*` - Alexa integration
     - `/api/voice-assistant/siri/*` - Siri integration

3. **JWT (JSON Web Tokens)**
   - **Purpose**: Secure voice session authentication
   - **Lifetime**: 24 hours (configurable)
   - **Payload**: User ID, role, permissions, session data

4. **MongoDB**
   - **Purpose**: Persistent storage
   - **Collections**:
     - `devices`: Device configurations
     - `activitylogs`: Voice command history
     - `rolepermissions`: Role-based access control

---

## üéØ Core Features

### 1. Natural Language Processing (NLP)

**Command Interpretation Pipeline:**

```javascript
Raw Speech ‚Üí Normalization ‚Üí Action Detection ‚Üí Device Matching ‚Üí Switch Selection ‚Üí Execution
```

**Supported Actions:**
- **Turn ON**: "turn on", "switch on", "power on", "enable", "activate", "start"
- **Turn OFF**: "turn off", "switch off", "power off", "disable", "deactivate", "shut down"
- **Toggle**: "toggle", "flip", "change", "invert"
- **Status**: "status", "state", "is", "check", "what's", "show"

**Example Commands:**
```
‚úÖ "Turn on the lights in IOT Lab"
‚úÖ "Switch off all fans"
‚úÖ "Toggle projector"
‚úÖ "What's the status of Light 1"
‚úÖ "Turn on fan 2 and light 3"  // Batch command
‚úÖ "Turn off everything in Computer Lab"
```

### 2. Context Management (Follow-up Commands)

**Per-User Context Storage:**
```javascript
{
  userId: "user123",
  lastDeviceId: "device_abc",
  lastSwitchIds: ["switch_1", "switch_2"],
  lastRoom: "IOT Lab",
  lastAction: "on",
  lastCommand: "turn on lights",
  updatedAt: 1699876543210
}
```

**Follow-up Examples:**
```
User: "Turn on lights in IOT Lab"
System: ‚úÖ "Turned ON 3 lights in IOT Lab"

User: "Turn them off"  // Pronoun reference
System: ‚úÖ "Turned OFF 3 lights in IOT Lab"  // Uses context

User: "Check their status"  // Pronoun reference
System: ‚úÖ "Light 1: OFF, Light 2: OFF, Light 3: OFF"
```

### 3. Bulk Operation Confirmation

**Safety Feature**: Prevents accidental mass shutdowns

**Triggers Confirmation When:**
- 3+ switches affected
- Multiple devices involved
- "All" keyword used with multiple matches

**Confirmation Flow:**
```
User: "Turn off all lights"
System: ‚ö†Ô∏è "About to turn OFF 5 lights in IOT Lab. Say 'confirm' to proceed."

User: "confirm"
System: ‚úÖ "Turned OFF 5 lights in IOT Lab"
```

**Confirmation Expires**: 60 seconds

### 4. Batch Commands

**Multiple Actions in Single Command:**
```
‚úÖ "Turn on fan 1 and light 2"
‚úÖ "Switch off projector then turn on AC"
‚úÖ "Enable light 1 plus fan 2"
```

**Processing:**
- Splits command by separators: "and", "then", "also", "plus"
- Executes each sub-command sequentially
- Returns aggregated results

### 5. Device Discovery & Matching

**Multi-Field Fuzzy Matching:**
- Device name: "IOT_Lab", "Computer Lab"
- Classroom: "MCA", "BCA 1st Sem"
- Location: "Building A", "Block D"
- Floor: "1", "2", "Ground"
- Voice aliases: Custom user-defined names

**Smart Switch Selection:**
- By name: "Light 1", "Fan 2"
- By type: "lights", "fans", "projector"
- By number: "Switch 1", "Relay 2"
- By context: "it", "them", "those"

**Access Control:**
- **Super-Admin/Admin/Dean**: Full access to all devices
- **Faculty**: Access to assigned classrooms + assigned devices
- **Student**: Access to assigned devices only

### 6. Voice Assistant Integration

#### Google Assistant (Smart Home API)

**Supported Intents:**
- `action.devices.SYNC`: Device discovery
- `action.devices.QUERY`: State queries
- `action.devices.EXECUTE`: Control commands

**Device Types:**
- `action.devices.types.LIGHT` (lights)
- `action.devices.types.FAN` (fans)
- `action.devices.types.OUTLET` (outlets)
- `action.devices.types.SWITCH` (projectors)
- `action.devices.types.AC_UNIT` (air conditioners)

**Traits:**
- `action.devices.traits.OnOff`: Binary state control

**Example Setup:**
```
User: "Hey Google, sync my devices"
Google: "Syncing AutoVolt devices..."
Google: "Found 15 devices from AutoVolt IoT"

User: "Hey Google, turn on IOT Lab lights"
Google: "Turning on 3 lights in IOT Lab"
```

#### Amazon Alexa (Smart Home Skill)

**Supported Namespaces:**
- `Alexa.Discovery`: Device enumeration
- `Alexa.PowerController`: Switch control
- `Alexa`: State reporting

**Capabilities:**
- `Alexa.PowerController`: ON/OFF control
- `Alexa.EndpointHealth`: Connectivity status

**Example Setup:**
```
User: "Alexa, discover devices"
Alexa: "Discovering devices... Found 15 smart home devices"

User: "Alexa, turn off Computer Lab fan"
Alexa: "OK"
```

#### Siri/HomeKit (Webhook Integration)

**Supported Intents:**
- `turn_on`: Activate device
- `turn_off`: Deactivate device
- `get_status`: Query state

**Example Setup:**
```
User: "Hey Siri, turn on the projector"
Siri: "Done"

User: "Hey Siri, what's the status of the lights?"
Siri: "Light 1 is off, Light 2 is on"
```

---

## üîê Security & Authentication

### Session-Based Authentication

**Voice Token Generation:**
```javascript
{
  voiceToken: "vt_abc123xyz",  // Unique session identifier
  expiresAt: "2025-11-13T10:30:00Z",
  userId: "user123",
  role: "faculty",
  permissions: {
    canControlDevices: true,
    canViewDeviceStatus: true,
    canCreateSchedules: false,
    canQueryAnalytics: false,
    canAccessAllDevices: false,
    restrictToAssignedDevices: true
  }
}
```

**Authentication Flow:**
1. User logs in (JWT token issued)
2. Request voice session: `POST /api/voice-assistant/session/create`
3. Voice token returned (separate from JWT)
4. Voice commands include voice token in requests
5. Backend validates token + permissions per command

### Role-Based Permissions

**Permission Matrix:**

| Feature | Super-Admin | Admin | Dean | Faculty | Student |
|---------|-------------|-------|------|---------|---------|
| Control All Devices | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |
| Control Assigned Devices | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| View Device Status | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| Create Schedules | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |
| Query Analytics | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |

**Permission Validation:**
```javascript
// Every voice command checks permissions
if (!voicePermissions.canControlDevices) {
  return { success: false, message: "You don't have permission to control devices" };
}

if (voicePermissions.restrictToAssignedDevices) {
  // Filter devices to only assigned ones
  devices = devices.filter(device => 
    device.assignedUsers.includes(userId) ||
    user.assignedRooms.includes(device.classroom)
  );
}
```

### Rate Limiting

**Protection Against Abuse:**
- **Limit**: 100 commands per 15 minutes per user
- **Implementation**: Express middleware with in-memory store
- **Behavior**: Returns 429 Too Many Requests when exceeded

```javascript
voiceRateLimit(100, 15 * 60 * 1000)  // 100 commands / 15 minutes
```

---

## üìä Analytics & Logging

### Activity Logging

**Every Voice Command Logged:**
```javascript
{
  action: "voice_command",  // or bulk_on, bulk_off, status_check
  deviceId: "device_abc",
  deviceName: "IOT_Lab",
  switchId: "switch_1",
  switchName: "Light 1",
  triggeredBy: "voice_assistant",
  userId: "user123",
  userName: "John Doe",
  timestamp: "2025-11-12T14:30:00Z",
  context: {
    assistant: "web",  // or "google", "alexa", "siri"
    command: "turn on the lights in IOT Lab",
    actionType: "on",
    desiredState: true,
    previousState: false,
    success: true,
    latencyMs: 234,
    operationsCount: 3,
    interpretation: {
      normalized: "turn on lights iot lab",
      devicePhrase: "iot lab",
      roomPhrase: "iot lab",
      switchHints: { type: "light", isPlural: true },
      scope: "all"
    },
    sessionInfo: {
      commandCount: 5,
      sessionAge: "2025-11-12T14:00:00Z"
    }
  }
}
```

### Voice Event Logging (UX Analytics)

**Client-Side Events:**
```javascript
{
  action: "voice_event",
  triggeredBy: "voice_assistant",
  context: {
    level: "info",  // or "warn", "error"
    stage: "recognition_started",  // lifecycle stage
    message: "Speech recognition started",
    data: { language: "en-US" },
    clientTimestamp: 1699876543210
  }
}
```

**Tracked Stages:**
- `recognition_started`: Listening initiated
- `interim_result`: Partial transcription
- `final_result`: Complete transcription
- `command_sent`: Sent to backend
- `command_success`: Successful execution
- `command_error`: Execution failed
- `recognition_error`: Speech API error

### Analytics Endpoints

**Voice Usage Metrics:**
- `GET /api/analytics/voice/summary?days=7`
  - Total commands, success rate, unique users/devices
  - Average latency, commands by assistant type
  
- `GET /api/analytics/voice/timeseries?granularity=hour&days=7`
  - Hourly/daily command volume trends
  
- `GET /api/analytics/voice/top-intents?limit=10&days=7`
  - Most common command types
  
- `GET /api/analytics/voice/top-errors?limit=10&days=7`
  - Most frequent failure reasons

---

## üîß Technical Implementation Details

### Frontend Voice Recognition

**Web Speech API Integration:**
```typescript
// Initialize recognition
const recognition = new webkitSpeechRecognition();
recognition.continuous = true;  // Keep listening
recognition.interimResults = true;  // Show partial results
recognition.lang = 'en-US';
recognition.maxAlternatives = 1;

// Event handlers
recognition.onstart = () => {
  console.log('Voice recognition started');
};

recognition.onresult = (event) => {
  const result = event.results[event.results.length - 1];
  const transcript = result[0].transcript;
  
  if (result.isFinal) {
    // Process final command
    processVoiceCommand(transcript);
  } else {
    // Show interim result
    showInterimTranscript(transcript);
  }
};

recognition.onerror = (event) => {
  console.error('Voice recognition error:', event.error);
};
```

### Backend Command Processing

**Processing Pipeline:**
```javascript
async function processVoiceCommand(command, deviceName, switchName, user) {
  // 1. Interpret command
  const interpretation = interpretVoiceCommand(command);
  
  // 2. Check for batch commands
  if (interpretation.isBatch) {
    return processBatchCommands(interpretation.batchCommands, user);
  }
  
  // 3. Handle confirmation
  if (interpretation.isConfirmation) {
    return handleConfirmation(user);
  }
  
  // 4. Apply context
  const context = getUserVoiceContext(user.id);
  if (interpretation.usesPronoun && context) {
    interpretation.devicePhrase = context.lastRoom;
  }
  
  // 5. Match devices
  let devices = await Device.find(buildDeviceQuery(user));
  devices = filterDevicesByPhrase(devices, interpretation.roomPhrase);
  
  // 6. Select switches
  const targets = [];
  for (const device of devices) {
    const switches = selectSwitchesForDevice(
      device, 
      switchName, 
      interpretation, 
      interpretation.scope, 
      context
    );
    targets.push(...switches.map(sw => ({ device, switch: sw })));
  }
  
  // 7. Check bulk confirmation requirement
  if (requiresBulkConfirmation(targets, interpretation)) {
    setPendingConfirmation(user.id, { operations: targets });
    return { success: false, message: "Say 'confirm' to proceed" };
  }
  
  // 8. Execute commands
  const results = [];
  for (const target of targets) {
    const result = await toggleDeviceSwitch(
      target.device._id, 
      target.switch._id, 
      interpretation.action === 'on'
    );
    results.push(result);
  }
  
  // 9. Update context
  setUserVoiceContext(user.id, {
    lastDeviceId: targets[0].device._id,
    lastRoom: targets[0].device.classroom,
    lastAction: interpretation.action
  });
  
  // 10. Return results
  return aggregateResults(results);
}
```

### Device-Switch Toggle Flow

```javascript
async function toggleDeviceSwitch(deviceId, switchId, state) {
  // 1. Update database
  const device = await Device.findOneAndUpdate(
    { _id: deviceId, 'switches._id': switchId },
    { 
      $set: { 
        'switches.$.state': state,
        'switches.$.lastStateChange': new Date()
      } 
    },
    { new: true }
  );
  
  // 2. Send MQTT command to ESP32
  if (device.status === 'online' && global.sendMqttSwitchCommand) {
    const switchData = device.switches.id(switchId);
    const gpio = switchData.relayGpio || switchData.gpio;
    
    global.sendMqttSwitchCommand(
      device.macAddress,  // ESP32 MAC address
      gpio,               // GPIO pin number
      state               // true/false
    );
  }
  
  // 3. Emit WebSocket update to connected clients
  io.to(`device_${deviceId}`).emit('device_state_changed', {
    deviceId,
    switchId,
    state
  });
  
  return { success: true, message: 'Switch updated' };
}
```

---

## üöÄ Usage Examples

### Web Interface

**Basic Commands:**
```
üé§ "Turn on the lights"
   ‚Üí Finds default room or prompts for room

üé§ "Switch off all fans in Computer Lab"
   ‚Üí Turns off all fan-type switches in Computer Lab

üé§ "Toggle projector"
   ‚Üí Flips projector state (ON‚ÜíOFF or OFF‚ÜíON)

üé§ "What's the status of Light 1 in IOT Lab"
   ‚Üí Reports: "Light 1 is currently OFF"
```

**Advanced Commands:**
```
üé§ "Turn on Light 1 and Fan 2 in IOT Lab"
   ‚Üí Batch command: turns on both switches

üé§ "Turn off everything in MCA classroom"
   ‚Üí Bulk command: prompts for confirmation

üé§ User: "Turn on lights in IOT Lab"
   ‚Üí ‚úÖ "Turned ON 3 lights"
   
   üé§ "Turn them off"  // Follow-up
   ‚Üí ‚úÖ "Turned OFF 3 lights"  // Uses context

üé§ "Turn off lights" (from IOT Lab)
   ‚Üí Uses your location/assigned room as context
```

### Google Assistant

```
üë§ "Hey Google, turn on IOT Lab lights"
ü§ñ "Turning on 3 lights in IOT Lab"

üë§ "Hey Google, is the Computer Lab projector on?"
ü§ñ "The projector is currently off"

üë§ "Hey Google, turn off all lights"
ü§ñ "OK, turning off 15 lights"
```

### Amazon Alexa

```
üë§ "Alexa, turn on the fan in room 101"
ü§ñ "OK"

üë§ "Alexa, turn off Computer Lab"
ü§ñ "Turning off 5 devices in Computer Lab"

üë§ "Alexa, discover devices"
ü§ñ "Found 15 smart home devices from AutoVolt"
```

### Siri/HomeKit

```
üë§ "Hey Siri, turn on the projector"
ü§ñ "Done"

üë§ "Hey Siri, what's the status of the lights?"
ü§ñ "Light 1 is off, Light 2 is on, Light 3 is on"

üë§ "Hey Siri, turn off everything"
ü§ñ "OK, I've turned off 10 devices"
```

---

## üîß Configuration

### Backend Configuration

**Environment Variables:**
```env
# Voice Control Settings
VOICE_SESSION_EXPIRY=86400000  # 24 hours in ms
VOICE_RATE_LIMIT=100           # Max commands per window
VOICE_RATE_WINDOW=900000       # 15 minutes in ms
VOICE_CONFIRMATION_TTL=60000   # 60 seconds for bulk confirmations

# Voice Assistant Integration
GOOGLE_HOME_PROJECT_ID=your_project_id
GOOGLE_HOME_CLIENT_SECRET=your_secret

ALEXA_SKILL_ID=your_skill_id
ALEXA_CLIENT_SECRET=your_secret

HOMEKIT_PIN=123-45-678
```

### Role Permissions Configuration

**Example MongoDB Document:**
```javascript
{
  role: "faculty",
  metadata: {
    displayName: "Faculty Member",
    description: "Teaching staff with classroom access",
    isActive: true
  },
  voiceControl: {
    enabled: true,
    canControlDevices: true,
    canViewDeviceStatus: true,
    canCreateSchedules: false,
    canQueryAnalytics: false,
    canAccessAllDevices: false,
    restrictToAssignedDevices: true
  }
}
```

### Device Voice Aliases

**Custom Names for Devices/Switches:**
```javascript
{
  name: "Light 1",
  voiceAliases: [
    "Main Light",
    "Front Light",
    "Classroom Light",
    "Big Light"
  ]
}
```

---

## üìà Performance Metrics

### Latency Breakdown

```
User Speech ‚Üí Recognition ‚Üí Processing ‚Üí Execution
   ~2-3s        ~100-300ms    ~200-500ms    ~100-200ms

Total Average Latency: 2.5-4 seconds
```

**Optimization Techniques:**
- Interim results for real-time feedback
- Fuzzy matching with optimized thresholds
- Database query optimization with indexes
- MQTT retained messages for faster device state sync

### Accuracy Metrics

**Intent Recognition:**
- **Simple Commands**: 95% accuracy ("turn on lights")
- **Complex Commands**: 85% accuracy ("turn on Light 2 and Fan 1")
- **Batch Commands**: 90% accuracy (with separators)
- **Follow-up Commands**: 92% accuracy (with context)

**Device Matching:**
- **Exact Match**: 98% accuracy
- **Fuzzy Match**: 85% accuracy (threshold 0.4)
- **Voice Alias**: 95% accuracy

---

## üêõ Error Handling

### Common Errors & Solutions

**1. No Microphone Access**
```
Error: "Microphone permission denied"
Solution: Enable microphone in browser settings
```

**2. Network Error**
```
Error: "Failed to connect to voice service"
Solution: Check internet connection, verify backend is running
```

**3. Device Not Found**
```
Error: "Couldn't find device 'XYZ'"
Solution: Try full device name or room name
Suggestion: "Try: 'turn on lights in IOT Lab'"
```

**4. Ambiguous Command**
```
Error: "Found multiple devices matching 'lab'"
Solution: Be more specific
Suggestion: "Try: 'turn on lights in IOT Lab'"
```

**5. Permission Denied**
```
Error: "You don't have permission to control this device"
Solution: Contact admin to assign device access
```

**6. Rate Limit Exceeded**
```
Error: "Too many commands. Please wait."
Solution: Wait 15 minutes or contact admin
```

---

## üîÆ Future Enhancements

### Planned Features

1. **Multi-Language Support**
   - Hindi, Tamil, Telugu, Kannada voice recognition
   - Transliteration support

2. **Voice Training**
   - User-specific voice profiles
   - Accent adaptation

3. **Scheduled Voice Commands**
   - "Turn on lights tomorrow at 8 AM"
   - "Schedule AC to start 30 minutes before class"

4. **Advanced NLP**
   - Sentiment analysis
   - Intent confidence scoring
   - Contextual learning

5. **Voice Biometrics**
   - Speaker identification for enhanced security
   - Voice-based authentication

6. **Offline Mode**
   - Local voice processing
   - Command queuing and sync

---

## üìö API Reference

### Voice Session Management

#### Create Voice Session
```http
POST /api/voice-assistant/session/create
Authorization: Bearer <jwt_token>

Response:
{
  "success": true,
  "data": {
    "voiceToken": "vt_abc123",
    "expiresAt": "2025-11-13T10:30:00Z"
  },
  "permissions": {
    "canControlDevices": true,
    "canViewDeviceStatus": true,
    ...
  }
}
```

#### List Active Sessions
```http
GET /api/voice-assistant/session/list
Authorization: Bearer <jwt_token>

Response:
{
  "success": true,
  "data": {
    "sessions": [
      {
        "voiceToken": "vt_abc123",
        "createdAt": "2025-11-12T10:30:00Z",
        "expiresAt": "2025-11-13T10:30:00Z"
      }
    ],
    "total": 1
  }
}
```

#### Revoke Voice Session
```http
DELETE /api/voice-assistant/session/revoke
Authorization: Bearer <jwt_token>
Content-Type: application/json

{
  "voiceToken": "vt_abc123"
}

Response:
{
  "success": true,
  "data": {
    "revoked": true,
    "message": "Voice session revoked"
  }
}
```

### Voice Command Processing

#### Process Voice Command
```http
POST /api/voice-assistant/voice/command
Authorization: Bearer <jwt_token>
X-Voice-Token: <voice_token>
Content-Type: application/json

{
  "command": "turn on lights in IOT Lab",
  "deviceName": "IOT Lab",  // optional
  "switchName": "Light 1",  // optional
  "assistant": "web"  // "web", "google", "alexa", "siri"
}

Response (Success):
{
  "success": true,
  "message": "Turned ON 3 lights in IOT Lab",
  "actionType": "bulk",
  "operations": [
    {
      "device": { "id": "...", "name": "IOT_Lab" },
      "switch": { "id": "...", "name": "Light 1" },
      "desiredState": true,
      "previousState": false,
      "success": true
    },
    ...
  ],
  "interpretation": {
    "normalized": "turn on lights iot lab",
    "devicePhrase": "iot lab",
    "action": "on",
    "scope": "all"
  }
}

Response (Confirmation Required):
{
  "success": false,
  "message": "About to turn OFF 5 lights in IOT Lab. Say 'confirm' to proceed.",
  "actionType": "confirmation_required",
  "context": {
    "pendingConfirmation": {
      "summary": "Turn OFF 5 lights",
      "expiresAt": "2025-11-12T14:31:00Z",
      "operations": 5
    }
  }
}

Response (Error):
{
  "success": false,
  "message": "Couldn't find device 'XYZ'",
  "actionType": "lookup_failed",
  "context": {
    "interpretation": { ... }
  }
}
```

### Voice Analytics

#### Get Voice Usage Summary
```http
GET /api/analytics/voice/summary?days=7
Authorization: Bearer <jwt_token>

Response:
{
  "range": { "days": 7 },
  "totals": {
    "totalCommands": 156,
    "successCount": 142,
    "successRate": 91.03,
    "uniqueUsers": 12,
    "uniqueDevices": 8,
    "avgLatencyMs": 234.5
  },
  "byAssistant": {
    "web": 120,
    "google": 25,
    "alexa": 11
  },
  "devices": [
    {
      "deviceId": "...",
      "total": 45,
      "success": 42,
      "failures": 3,
      "successRate": 93.33,
      "assistants": ["web", "google"],
      "lastCommand": "2025-11-12T14:30:00Z"
    },
    ...
  ]
}
```

---

## ü§ù Contributing

### Adding New Voice Commands

1. **Update Action Synonyms** (backend/controllers/voiceAssistantController.js):
```javascript
const ACTION_SYNONYMS = {
  // ... existing ...
  schedule: ['schedule', 'set timer', 'program', 'automate']
};
```

2. **Add Intent Parser** (src/lib/voiceIntents.ts):
```typescript
if (cleaned.includes('schedule')) {
  type = 'SCHEDULE';
  // Extract time and device from command
}
```

3. **Implement Handler** (backend/controllers/voiceAssistantController.js):
```javascript
if (interpretation.action === 'schedule') {
  return await handleScheduleCommand(interpretation, user);
}
```

4. **Test Thoroughly**:
   - Unit tests for intent parsing
   - Integration tests for end-to-end flow
   - Manual testing with various phrasings

---

## üìû Support

**For Issues:**
- Backend voice processing: Check `backend/logs/voice-assistant.log`
- Frontend recognition: Check browser console
- MQTT communication: Check `backend/logs/mqtt.log`
- Device logs: Check ESP32 serial monitor

**For Questions:**
- Voice command not recognized? Try being more specific
- Device not responding? Check if it's online
- Permission denied? Contact your system administrator

---

**Version**: 1.0.0  
**Last Updated**: November 12, 2025  
**Maintained By**: AutoVolt IoT Team

